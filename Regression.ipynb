{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "from sklearn import linear_model, svm, kernel_ridge\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions to load, clean, substract mean of data, split datasets, print the classification rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # load data from csv file (stratpy not available)\n",
    "    prices_raw = pd.read_csv(\"./Prices_raw.csv\")\n",
    "\n",
    "    # parse timestamps correctly\n",
    "    for t in [u'date' , u'ebsMarketUpdateTime', u'feedHandlerPublishTime', u'feedHandlerReceiveTime', u'eventCaptureTime']:\n",
    "        prices_raw[t] = pd.to_datetime(prices_raw[t])\n",
    "    \n",
    "    return prices_raw\n",
    "\n",
    "def clean_data(prices_raw):\n",
    "    prices = prices_raw[['date','bid','ask','bid2','ask2','bid3','ask3','bidSize1','askSize1','bidSize2','askSize2','bidSize3','askSize3']]\n",
    "\n",
    "    prices['bid'] = prices['bid'].replace(0,np.NaN)\n",
    "    prices['ask'] = prices['ask'].replace(0,np.NaN)\n",
    "    prices['bid2'] = prices['bid2'].replace(0,np.NaN)\n",
    "    prices['ask2'] = prices['ask2'].replace(0,np.NaN)\n",
    "\n",
    "    prices['mid'] = 0.5*(prices['bid'] + prices['ask'])\n",
    "    prices.index = prices_raw.feedHandlerReceiveTime\n",
    "\n",
    "    return prices \n",
    "    # columns: feedHandlerReceiveTime | bid, ask, bid2, ask2, bid3, ask3, bidSize1, askSize1, bidSize2, askSize2, bidSize3, askSize3, paid, given, mid\n",
    "\n",
    "def whiten_data(prices):\n",
    "    mean_price = np.round(prices['mid'].mean(), 4)\n",
    "    block_size = 1e6\n",
    "\n",
    "    prices[['bid', 'ask', 'bid2', 'ask2', 'bid3', 'ask3', 'mid']] -= mean_price\n",
    "    prices[['bidSize1', 'askSize1', 'bidSize2', 'askSize2', 'bidSize3', 'askSize3']] /= block_size\n",
    "    \n",
    "    return prices\n",
    "\n",
    "def split_test_train(prices, dep_var):\n",
    "    # IN = row indices for train, OUT = for test\n",
    "    OUT = (prices.date == '2017.09.29') | (prices.date == '2017.09.28') \n",
    "    OUT = OUT | (prices.date == '2017.09.27') \n",
    "    IN = ~OUT\n",
    "\n",
    "    X_train = prices[IN]\n",
    "    X_train.drop(['date'], 1, inplace = True) # drop the date in order to keep a multivariate input\n",
    "    cols = list(X_train.columns)\n",
    "    X_train = np.array(X_train.values)\n",
    "    y_train = np.array(dep_var[IN]['nextMidVariation'].values)\n",
    "    \n",
    "    X_test = prices[OUT]\n",
    "    X_test.drop(['date'], 1, inplace = True)\n",
    "    X_test = np.array(X_test.values)\n",
    "    y_test = np.array(dep_var[OUT]['nextMidVariation'].values)\n",
    "\n",
    "    y_train[y_train<0] = -1\n",
    "    y_train[y_train>0] = 1\n",
    "    y_test[y_test<0] = -1\n",
    "    y_test[y_test>0] = 1\n",
    "\n",
    "    return X_train, y_train, np.array(dep_var[IN]['nextMidVariation'].values), X_test, y_test, np.array(dep_var[OUT]['nextMidVariation'].values), cols\n",
    "\n",
    "def classif_correct_rate(estim, truth):\n",
    "    return 1.0 - np.linalg.norm(np.sign(estim) - truth, ord = 1) / (2 * estim.shape[0])\n",
    "\n",
    "def print_statistics(y_train, y_test):\n",
    "    print('Prior dataset statistics')\n",
    "    print('train: +1: %.3f, -1: %.3f'   % (np.sum(y_train[y_train > 0]) / y_train.shape[0], np.sum(y_train[y_train < 0]) / y_train.shape[0]))\n",
    "    print('test:  +1: %.3f, -1: %.3f\\n' % (np.sum(y_test[y_test > 0]) / y_test.shape[0], np.sum(y_test[y_test < 0]) / y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features engineering: add columns containing moving averages etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_engineering(prices):\n",
    "    # spread \n",
    "    prices['spread'] = prices['ask'] - prices['bid']\n",
    "\n",
    "    # book pressure feature\n",
    "    prices['bp'] = prices['mid'] - (prices['bidSize1']*prices['bid'] + prices['askSize1']*prices['ask'])/(prices['bidSize1']+prices['askSize1'])\n",
    "    prices['bp_with2'] = prices['mid'] - (prices['bidSize1']*prices['bid'] + prices['askSize1']*prices['ask']\n",
    "                                                     + prices['askSize2']*prices['ask2'] + prices['askSize3']*prices['ask3']\n",
    "                                                     + prices['bidSize2']*prices['bid2'] + prices['bidSize3']*prices['bid3'])/(prices['bidSize1']+prices['askSize1']+prices['bidSize2']+prices['askSize2']+prices['bidSize3']+prices['askSize3'])\n",
    "\n",
    "\n",
    "    prices['weekday'] = prices.index.weekday\n",
    "    \n",
    "    # volatility\n",
    "    vol_lookbacks = [1e3, 1e5, 1e7, 1e9]\n",
    "    for lookback in vol_lookbacks:\n",
    "        prices['mid_vol_%d_ms' % lookback] = prices['mid'].rolling('%dms' % lookback).std()\n",
    "        prices['mid_vol_%d_ms' % lookback].ffill()\n",
    "\n",
    "    # column name over which we build moving averages\n",
    "    columns = ['bid','ask','bid2','ask2','bidSize1','askSize1','bidSize2','askSize2','mid','spread', 'bp', 'bp_with2']\n",
    "    columns = ['bidSize1','askSize1','mid','spread','bp_with2']\n",
    "    \n",
    "    #moving averages over last n rows\n",
    "    row_intervals = [1, 5, 10, 320, 1280]\n",
    "    for window in row_intervals:\n",
    "        for feature in columns:\n",
    "            prices['%s_ma_%d_row' % (feature, window)] = prices[feature].rolling(window, min_periods=1).mean()\n",
    "            prices['mid_vol_%d_ms' % lookback].ffill()\n",
    "\n",
    "    # moving averages over last n milliseconds\n",
    "    time_intervals = [20, 80, 1000, 16000] \n",
    "    for time_window in time_intervals:\n",
    "        for feature in columns:\n",
    "            prices['%s_ma_%d_ms' % (feature, time_window)] = prices[feature].rolling('%ds' % time_window, min_periods=1).mean()\n",
    "            prices['%s_ma_%d_ms' % (feature, time_window)]\n",
    "    \n",
    "    # columns over which we'll build delta /deltadelta signals\n",
    "    for col in ['spread', 'bid', 'ask']:\n",
    "        if col in columns:\n",
    "            columns.remove(col)\n",
    "    ma_row_columns = ['%s_ma_%d_row' % (feature, window) for feature in columns for window in row_intervals]\n",
    "    ma_ms_columns = ['%s_ma_%d_ms' % (feature, time_window) for feature in columns for time_window in time_intervals]\n",
    "    ma_columns = ma_row_columns + ma_ms_columns\n",
    "\n",
    "    # columns to differentiate once\n",
    "    ma_columns += ['mid']\n",
    "    delta_column_names = ['delta_' + col for col in ma_columns]\n",
    "    prices[delta_column_names] = prices[ma_columns] - prices[ma_columns].shift(1)\n",
    "    # columns to differentiate twice\n",
    "    delta_delta_column_names = ['delta_' + col for col in delta_column_names]\n",
    "    prices[delta_delta_column_names] = prices[delta_column_names] - prices[delta_column_names].shift(1)\n",
    "\n",
    "    # drop first two rows since they're nan for the delta_delta\n",
    "    prices = prices.iloc[2:]\n",
    "\n",
    "    prices['mid_diff_interval'] = (prices['delta_mid'] != 0).cumsum()\n",
    "\n",
    "    old_n_rows = prices.shape[0]\n",
    "    prices.dropna(inplace=True)\n",
    "    print 'Dropped %d out of %d rows containing NaNs' % (old_n_rows - prices.shape[0], old_n_rows)\n",
    "    old_n_rows = prices.shape[0]\n",
    "    prices = prices[(np.abs(stats.zscore(prices['delta_mid'])) < 5)]\n",
    "    print 'Dropped %d out of %d rows with extreme z-score' % (old_n_rows - prices.shape[0], old_n_rows)\n",
    "\n",
    "    ######### create feature to learn, ie next move (not to be used as covariates!)\n",
    "    prices['midDiff'] = prices['mid'].diff()\n",
    "    prices['nextMidDiff'] = prices['midDiff'].shift(-1)\n",
    "    prices['nextMidVariation'] = prices['nextMidDiff'].replace(to_replace=0, method='bfill')\n",
    "    # drop nans again (there may be new nan's in nextMidVariation?)\n",
    "    old_n_rows = prices.shape[0]\n",
    "    prices.dropna(inplace=True)\n",
    "    print 'Dropped %d out of %d rows containing NaNs\\n' % (old_n_rows - prices.shape[0], old_n_rows)\n",
    "\n",
    "    mid_look_ahead = prices[['nextMidVariation']]\n",
    "    # drop variables which should not be used as covariates\n",
    "    #Â prices.drop(['midDiff'], 1, inplace = True)\n",
    "    prices.drop(['nextMidDiff'], 1, inplace = True)\n",
    "    prices.drop(['nextMidVariation'], 1, inplace = True)\n",
    "\n",
    "    return prices, mid_look_ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 87792 out of 231152 rows containing NaNs\n",
      "Dropped 982 out of 143360 rows with extreme z-score\n",
      "Dropped 5 out of 142378 rows containing NaNs\n",
      "\n",
      "Prior dataset statistics\n",
      "train: +1: 0.512, -1: -0.488\n",
      "test:  +1: 0.494, -1: -0.506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prices_raw = load_data()\n",
    "prices = clean_data(prices_raw)\n",
    "prices = whiten_data(prices)\n",
    "prices, dep_var = features_engineering(prices)\n",
    "X_train, y_train, y_train_value, X_test, y_test, y_test_value, cols = split_test_train(prices, dep_var)\n",
    "\n",
    "print_statistics(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prev_train = X_train[:, cols.index('midDiff')]\n",
    "y_prev_test = X_test[:, cols.index('midDiff')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.,  1.,  1., ...,  0.,  1.,  0.]),\n",
       " array([ 1.,  1., -1., ...,  1., -1., -1.]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign(y_prev_test), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
